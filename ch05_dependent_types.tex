
\chapter{DEPENDENT TYPES}\label{ch:dependenttypes}
It is time to wrap up my undergraduate thesis. In this post I'll cover the two remaining axes of the lambda cube, $\omega $ and $P $. First, a brief introduction to the type operators of $\lambda_\omega $. Then on to Algebraic Data Types, which make use of type operators. ADT's generalization, Generalized Algebraic Data Types, will then carry us into Dependent Types ($\lambda_P $ or $\lambda_\Pi $).

\section{Dependent Types in a Nutshell}
So far we have seen terms that depend on terms (lambda abstractions), terms that depend on types (polymorphism and simple type abstractions), and soon I'll cover types that depend on types (type operators). This leaves one additional possibility, types that depend on terms, or dependent types. Having types that depend on terms lets us move a lot of a program's computation into the type checker, yielding crazy possibilities: lists that carry their length in their type [3], an AVL tree implementation whose type guarantees certain balanced properties [5], a sorting algorithms whose type proves well-ordered output [6], and so on. But first let's explore the $\lambda_\omega $ system.

\section{Type Operators}
Suppose you want to create a new type from existing types. The lambda systems we've explored so far don't support this expressive of type level operations. System F lets us use simple type applications and abstractions to model polymorphism, but it doesn't allow for the creation of new types.

For instance, let's construct Haskell's Either type:
%<pre>
%<u><font color="Green">data</font></u> Either a b <font color="Blue">=</font> Left a <font color="Blue">|</font> Right b
%</pre>
This is an Algebraic Data Type (ADT). On the left is the type, where any two types can be substituted for $a$ and $b$. On the right are the two terms that inhabit that type. Formally, the type looks something like $Either\ Y\ Z = \forall X. (Y \rightarrow Z \rightarrow X) \rightarrow X $ or $\lambda Y. \lambda Z. \forall X. (Y \rightarrow Z \rightarrow X) \rightarrow X $, where $Y$ and $Z$ are type parameters and $X$ is the new type produced (as adapted from Chapter. 29 of [2]). $Either$ is a type that depends on other types. If we add some simple type application and abstraction rules we are good to go, right? 

Not really. We now have two types of types, proper types with arity of 0, as well as partially applied types, or type families, with arity greater than 0. Using type families in type signatures doesn't make sense, so we need to ensure that our type signatures are themselves well typed. So enters the notion of kinds.

\section{Kinds}
What is the type of a type? Let us denote it as a kind ($\ast $). The kind of a proper type is denoted $Int :: \ast $. Things get interesting now that we have type operators. The type constructor $Either$ is of the kind $\ast \rightarrow \ast \rightarrow \ast $. And of course you can curry type constructors: $Either\ Int\ :: \ast \rightarrow \ast $,

Going deeper, what is the type of a kind? Well according to [1]:

%<blockquote>
"As the kind of ∗ is itself ∗, we can encode a variation of Russell’s paradox, known as Girard’s paradox. This allows us to create an inhabitant of any type. To fix this, the standard solution is to introduce an infinite hierarchy of types: the type of ∗ is ∗1 , the type of ∗1 is ∗2 , and so forth."
%</blockquote>

So basically it is turtles all the way down...

\section{Generalized Algebraic Data Types (GADT)}
ADTs are great, but we might ask, can we squeeze more expressiveness out them? The answer is yes, and it comes in the form of GADTs.

The key distinction between ADTs and GADTs is that pattern matching causes type refinement. Take this contrived example of an ADT:

%<pre><u><font color="Green">data</font></u> Term' a <font color="Blue">=</font> Lit1 Int
             %<font color="Blue">|</font> Lit2 a
             %<font color="Blue">|</font> Succ' Int
%</pre>
and look at the type of the following:
%<pre>
%<font color="Blue">&gt;</font> <b><font color="Blue">:</font></b>t Lit1 <font color="Red">1</font>
%Lit1 <font color="Red">1</font> <font color="Blue">::</font> Term' a

%<font color="Blue">&gt;</font> <b><font color="Blue">:</font></b>t Lit2 <font color="Red">'a'</font>
%Lit2 <font color="Red">'a'</font> <font color="Blue">::</font> Term' Char
%</pre>

Constructing a $Lit1$ term doesn't lead to a type refinement of $a$ to $Int$ in $Term' a$. $Lit2$ does refine $a$ to $Char$ but this type refinement is too restrictive. Let's make a similar GADT, $Term a$, taken from [4], which uses it to define a well-typed eval function:

%<pre>
%<u><font color="Green">data</font></u> Term a <u><font color="Green">where</font></u>
  %Lit    <font color="Blue">::</font> Int <font color="Blue">-&gt;</font> Term Int
  %Succ   <font color="Blue">::</font> Term Int <font color="Blue">-&gt;</font> Term Int
  %IsZero <font color="Blue">::</font> Term Int <font color="Blue">-&gt;</font> Term Bool
  %If     <font color="Blue">::</font> Term Bool <font color="Blue">-&gt;</font> Term a <font color="Blue">-&gt;</font> Term a <font color="Blue">-&gt;</font> Term a
  %Pair   <font color="Blue">::</font> Term a <font color="Blue">-&gt;</font> Term b <font color="Blue">-&gt;</font> Term <font color="Blue">(</font>a<font color="Blue">,</font>b<font color="Blue">)</font>
%</pre>

$a$ is refined to $Int$ in the following GADT term:
%<pre>
%<font color="Blue">&gt;</font> <b><font color="Blue">:</font></b>t Lit <font color="Red">1</font>
%Lit <font color="Red">1</font> <font color="Blue">::</font> Term Int
%</pre>

And we gain some expressiveness by allowing $a$ to be refined to $Bool$ in $IsZero$:
%<pre><font color="Blue">&gt;</font> <b><font color="Blue">:</font></b>t IsZero <font color="Blue">$</font> Lit <font color="Red">1</font>
%IsZero <font color="Blue">$</font> Lit <font color="Red">1</font> <font color="Blue">::</font> Term Bool
%</pre>


\section{Faking dependent types with GADT}
In some instances we can use GADTs to fake dependent typing. Since GADTs separate values from types, that is, terms aren't allowed in type operations, we have to use singleton types that represent values [7]. This is the approach taken by Sheard et. al. in the design of Ωmega [7].

Take, for instance, this series of ADTs:
$data\ Vec0\ \alpha = Vec0 $
$data\ Vec1\ \alpha = Vec1\ \alpha $
$data\ Vec2\ \alpha = Vec2\ \alpha\ \alpha $
$data\ Vec3\ \alpha = Vec3\ \alpha\ \alpha\ \alpha $

These ADTs are trying to capture length information of the vector. There is a pattern here, and it would be nice to create an abstraction for it, such as: $\forall \alpha :: \ast.\forall n :: Nat.Vec\ n\ \alpha $, where $n$ represents the length, and $\alpha $ the data.[1]

Using GADTs we can create types to represent the natural numbers and successfully achieve the abstraction above. The following is an example modified from [3]:

%<pre>
%<font color="Green">-- Making use of phantom types</font>
%<u><font color="Green">data</font></u> Zero
%<u><font color="Green">data</font></u> Succ n

%<font color="Green">-- Some type aliases for convience</font>
%<u><font color="Green">type</font></u> One   <font color="Blue">=</font> Succ Zero
%<u><font color="Green">type</font></u> Two   <font color="Blue">=</font> Succ One
%<u><font color="Green">type</font></u> Three <font color="Blue">=</font> Succ Two
%<u><font color="Green">type</font></u> Four  <font color="Blue">=</font> Succ Three

%<u><font color="Green">data</font></u> Vec n a <u><font color="Green">where</font></u>
  %Nil  <font color="Blue">::</font> <font color="Blue">(</font>Show a<font color="Blue">)</font> <font color="Blue">=&gt;</font>                 Vec Zero a
  %Cons <font color="Blue">::</font> <font color="Blue">(</font>Show a<font color="Blue">)</font> <font color="Blue">=&gt;</font> a <font color="Blue">-&gt;</font> Vec n a <font color="Blue">-&gt;</font> Vec <font color="Blue">(</font>Succ n<font color="Blue">)</font> a

%<u><font color="Green">instance</font></u> Show <font color="Blue">(</font>Vec n a<font color="Blue">)</font> <u><font color="Green">where</font></u> show <font color="Blue">=</font> showVec

%showVec <font color="Blue">::</font> Vec n a <font color="Blue">-&gt;</font> String
%showVec Nil <font color="Blue">=</font> <font color="Red">""</font>
%showVec <font color="Blue">(</font>Cons x xs<font color="Blue">)</font> <font color="Blue">=</font> show x <font color="Blue">++</font> <font color="Red">" "</font> <font color="Blue">++</font> showVec xs

%foo <font color="Blue">=</font> Cons <font color="Red">3</font> <font color="Blue">(</font>Cons <font color="Red">2</font> <font color="Blue">(</font>Cons <font color="Red">1</font> Nil<font color="Blue">)</font><font color="Blue">)</font>

%<font color="Blue">&gt;</font> show foo
%<font color="Red">"3 2 1"</font>
%</pre>

This is pretty cool, and I've enjoyed playing around with Ωmega, which fully internalizes this approach. Regardless, things can get cumbersome when you have to create parallels between the type and term worlds.

\section{Pi Types}
In literature, the $\Pi $ type represents the dependent product type, and is a generalization of $\lambda $ in simply typed lambda calculus. It abstracts arrows, accepting type-level arguments, as well as term-level arguments. Hence $S \rightarrow T  $ is the same as $\Pi x : S\ .\ T $, where $x$ does not appear free in $T$.

According to [9], 1st order predicate logic is isomorphic to dependent types. A predicate $B$ over type $A$ is viewed as a type value function over $A$, and hence universal quantification is the same as dependent product: $\forall x : A . B(x) $ is equivalent to $\Pi x : A . B(x) $ 


\section{Challenges with Type Checking}
Dependent typing lets us move a lot of computation to the type checking phase, giving us the ability to construct more expressive proofs via the Curry-Howard Isomorphism. Unfortunately, we can't get all this proof-carrying code without incurring a cost. 

The main problem is that now there are terms in our types, so to check type equality we need to evaluate our types to a normal form. If we aren't careful and encode too powerful of a language into our types the result is a non-terminating type checker. Modern dependently type languages remedy this problem differently:
%<blockquote>
"Ωmega type-level programs are written as term rewriting systems, that have to terminate; Epigram and Coq programs are written in total languages - every program terminates; in Agda, programs are interrupted when they get stuck in a loop - soundness is regained through a separate termination check (I think). In practice, non-termination doesn't seem to be a big problem." [8]
%</blockquote>

Where total languages are those that provably terminate, and hence are not Turing-Complete, while partial languages are Turing-Complete.

So language designers must tread lightly. Total languages are restrictive and require a certain approach to problems, while partial languages require tricks to ensure termination and soundness of type checking.

\section{Are Dependent Types the Way to the Future?}
There is a lot of stigma against dependently typed languages:
%<blockquote>
"Most Haskell programmers are hesitant to program with dependent types. It is said that type checking becomes undecidable; the phase distinction between type checking and evaluation is lost; the type checker will always loop; and that dependent types are really, really hard.

The same Haskell programmers, however, are perfectly happy to program with a ghastly hodgepodge of generalized algebraic data types, multi-parameter type classes with functional dependencies, impredicative higher-ranked types, and even data kinds. They will go to great lengths to avoid dependent types." [1]
%</blockquote>

At the same time, a lot of smart people are pushing dependent types. For instance, [10] sees a dependently typed, pay-as-you-go approach to language verification as the next logical step in the progression of languages.

What is certain is that we have a long ways to go, in terms of both programmer intellect and language development, before we start seeing the adoption of these mind bending type systems.

%[1] <a href="http://people.cs.uu.nl/andres/LambdaPi/index.html">A tutorial implementation of a dependently typed lambda calculus</a>
%[2] <a href="http://www.cis.upenn.edu/~bcpierce/tapl/">Types and Programming Languages</a>
%[3] <a href="http://www.haskell.org/pipermail/haskell/2005-May/015815.html">Fixed-length vectors in Haskell, Part 1: Using GADTs</a>
%[4] <a href="http://www.haskell.org/ghc/docs/latest/html/users_guide/data-type-extensions.html#gadt">Haskell User Guide: Data Type Extensions</a>
%[5] <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.121.4251">Programming in Omega</a>
%[6] <a href="lambda-the-ultimate.org/node/693">Why Dependent Types Matter</a>
%[7] <a href="web.cecs.pdx.edu/~sheard/papers/GADT+ExtKinds.ps">GADTs + Extensible Kinds = Dependent Programming</a>
%[8] <a href="http://axisofeval.blogspot.com/2010/10/notes-on-dependent-types.html">http://axisofeval.blogspot.com/2010/10/notes-on-dependent-types.html</a>
%[9] <a href="http://www.cis.upenn.edu/~bcpierce/attapl/">Advanced Topics in Types and Programming Languages</a>
%[10] <a href="http://www.seas.upenn.edu/~sweirich/papers/foser10.pdf">Language-Based Verification Will Change The World</a>
