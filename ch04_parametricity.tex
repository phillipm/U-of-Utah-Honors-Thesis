\chapter{PARAMETRICITY}\label{ch:parametricity}
With universal quantification ($\forall $) over types, System F allows us to reason about polymorphic functions. System F's polymorphism is called \emph{parametric polymorphism}, as compared to the \emph{ad-hoc polymorphism} of method overloading in most imperative languages. The generality of this parametric polymorphism has much to offer.

\section{Theorems for Free}
In "Theorems for Free!" \cite{theoremsForFree}, Wadler refines some ideas on parametric polymorphism presented by Reynolds in \cite{reynolds}. The overarching idea is that parametrically polymorphic functions behave uniformly across all types. With this uniformity we can derive certain simple theorems from only the type signature.

Take this polymorphic function $f : \forall A . A \rightarrow A$
If we exclude the ability to do runtime type analysis \cite{vytinFree}, there is no way to do operations that distinguish between types. Hence, the only possible function body that could inhabit $f$ is the identity function $f = \lambda A\ .\ \lambda x : A\ .\ x $

Extending this idea to functions that operate over lists, a function such as $g : \forall A . [A] \rightarrow [A] $ can only operate over the elements provided to it.

Wadler, making use of this, shows that polymorphic functions in System F commute with all functions that operate on more specific types.

For instance, given function signatures
$f : \forall A . [A] \rightarrow [A] $
$g : Char \rightarrow Int $
then
$map\ g \circ f_{Char} \equiv f_{Int} \circ map\ g$

Below is a continuation of this example in Haskell using the ExistentialQuantification extension. We let $f$ be the $reverse$ function, and $g$ be $ord$, which takes characters to their ascii values.
\begin{SaveVerbatim}{para}
{-# LANGUAGE ExistentialQuantification #-}

f :: forall a . [a] -> [a]
f = reverse

g :: Char -> Int
g = ord

Main*> map g . f $ ['a'..'f']
  [102,101,100,99,98,97]

Main*> f . map g $ ['a'..'f']
  [102,101,100,99,98,97]
\end{SaveVerbatim}
\begin{figure}
  \BUseVerbatim{para}
  \caption{FOOBAR}
  \label{fig:const}
\end{figure}

\section{Pffft, tell me something useful}
While trivial looking, these simple commuting theorems are actually useful. They enable us to add function commutativity to our arsenal of algebraic manipulations when we are reasoning about programs \cite{theoremsForFree}. In addition, \cite{impreciseSemantics} states that the reordering of function applications can lead to improved efficiency of code by enabling additional transformations and analysis.

That's cool, but still kind of boring and aides little when using real world languages. So what's up with parametricity these days and can it be useful in the context of modern functional languages?

\section{Parametricity with Haskell}
You may have noticed by now that languages like Haskell have runtime type analysis, as well as imprecise error semantics, both of which prevent us from deriving free theorems from polymorphic functions.

By imprecise error semantics, we mean that the error raised by a program is not guaranteed to be the same exception that would be encountered by a straight forward sequential execution \cite{jonesSemantics}. This means that when making use of free theorems in Haskell, there is no guarantee that new errors will won't be introduced.

Take the example provided in Stenger and Voigtl√§nder's paper "Parametricity for Haskell with Imprecise Error Semantics" \cite{impreciseSemantics}:
\begin{SaveVerbatim}{imprecise}
-- produces ***Exception: divide by zero
l = [[i] | i <- [1..(div 1 0)]]

-- can produce *** Exception: Prelude:tail: empty list
tail

-- can only propagate errors
null
takeWhile

-- only propagates errors (This makes no sense to me!)
map tail

-- can possibly produce empty list or divide by zero errors
(takeWhile (null . tail) l)

-- by parametric free theorems:
map tail (takeWhile (null . tail) l) == 
takeWhile null (map tail l)

-- but this could produce 2 different errors
map tail (takeWhile (null . tail) l)

-- while this could only produce 1 error
takeWhile null (map tail l)
\end{SaveVerbatim}

\begin{figure}
  \BUseVerbatim{imprecise}
  \caption{FOOBAR}
  \label{fig:imprecise}
\end{figure}

\begin{SaveVerbatim}{maptail}
map tail
\end{SaveVerbatim}
\begin{SaveVerbatim}{maptail2}
map tail [[1], [], [2]]
\end{SaveVerbatim}

This example shows that Haskell's non-deterministic error semantics might introduce new errors when free theorems are used. The one problem I have with this example is the authors claim that \BUseVerbatim{maptail} only propagates errors and doesn't actually introduce any new errors. This disagrees with me because \BUseVerbatim{maptail2} will obviously raise an error. I'll have to take a deeper look at this. Regardless, \cite{impreciseSemantics} goes on to formulate notations for using free theorems in the presence of imprecise errors.

As for runtime type analysis, the essence of the problem is that polymorphic functions can treat inputs of different types non-uniformly. Hence there is no straight forward way to derive free theorems from polymorphic functions that analyze types, such as the function $f'$ derived from the example in \cite{vytinFree}:

\begin{SaveVerbatim}{noFree}
-- Without runtime type analysis functions of type a -> a
-- can only be inhabited by the identity
f :: forall a . a -> a
f x = x

-- With runtime type analysis anything is possible!
-- NOTE: This isn't actually valid Haskell,
-- but I couldn't figure out how to do runtime type analysis
f' :: forall a . a -> a
f' x = if (typeOf x) == (typeOf 1)
         then succ x
         else x

g :: forall a . a -> Int
g _ = 42

-- The free theorem for f and g:
f . g == g . f

-- No free theorem for f' and g since:
f' . g /= g . f'
\end{SaveVerbatim}

\begin{figure}
  \BUseVerbatim{noFree}
  \caption{FOOBAR}
  \label{fig:noFree}
\end{figure}

\cite{vytinFree} remedies this problem by using representation types. Languages such as $\lambda_R $ use term representation of types to simulate runtime type analysis \cite{erasureSemantics}. The idea is to have terms represent types, so if term $e$ represents type $t$, then term $e$ has type $R\ t$. The introduction of GADTs (generalized algebraic datatypes) has enabled representation types to be used with parametricity. This is best seen in the concrete with an example from \cite{vytinFree} that uses Haskell's GADT language extension:

\begin{SaveVerbatim}{rep}
-- representation type of Int, Func, and Any
data R a where
  Rint :: R Int
  Rarrow :: R a -> R b -> R (a -> b)
  Rany :: R a

-- runtime type analysis using representation types
g :: (R a) -> a -> a
g t y = case t of
             Rint -> succ y
             Rany -> y

> Rint 1
2

> Rany 'a'
'a'

> Rint 'a'
***Couldn't match expected type `Int' with actual type `Char'
\end{SaveVerbatim}

\begin{figure}
  \BUseVerbatim{rep}
  \caption{FOOBAR}
  \label{fig:rep}
\end{figure}

In the example above, the general free theorem $(g[\tau]\ r) \circ h \cong h \circ (g[\tau]\ r) $ doesn't hold because of $R_{int} $. But of course if we are analyzing $R_{any} $ it holds: $(g[\tau]\ (R_{any}[\tau])) \circ h \cong h \circ (g[\tau]\ (R_{any}[\tau])) $ \cite{vytinFree}

The work in \cite{vytinFree} starts to lay the theoretical foundations needed to start reasoning about complex languages such as Haskell in terms of parametricity.

\section{Parametricity and Program Synthesis}
This brings me to how parametricity might help with program synthesis. The simple parametrically polymorphic functions presented in \cite{theoremsForFree} seem much more tractable to synthesize when compared to functions with arbitrary type signatures. This is because the polymorphism guarantees that parameters will be treated uniformly and values external to the input exhibit little influence over the output. This greatly reduces the problem space.

But is synthesizing parametrically polymorphic functions actually useful? In most cases these functions are extremely simple and trivial, such as $tail$, $reverse$, $id$, etc. Future work (on GADTs), as discussed in \cite{vytinFree}, might lead to more nuanced and powerful reasoning of parametric polymorphism.

\section{Conclusion}
This post is spread quite thin; I've given an introduction to parametricity and free theorems, and shown how current research is working to make parametricity applicable to modern languages such as Haskell. Lastly I've punted on how parametricity might be useful to program synthesis.

Hopefully this has sparked your interest in parametricity. In addition to the papers I presented here, there is some really interesting research going on in this area. "Generalizing Parametricity Using Information-flow" \cite{infoFlow} looks to provide security and confidentiality to module writers utilizing parametric polymorphism in the face of runtime type analysis. "A Logic for Parametric Polymorphism" \cite{paraLogic} introduces a logic that formalizes parametric polymorphism and follows in the steps of LCF, taking the first steps towards creating a full fledged logic for polymorphic programs.
